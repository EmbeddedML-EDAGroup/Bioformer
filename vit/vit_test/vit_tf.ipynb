{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "worth-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.datasets.db6 import DB6MultiSession\n",
    "from pickle import load\n",
    "\n",
    "import os\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# MODEL\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self._init_parameters(dim, hidden_dim)\n",
    "\n",
    "    def _init_parameters(self, dim, hidden_dim):\n",
    "        bound1 = 1 / (dim ** .5)\n",
    "        bound2 = 1 / (hidden_dim ** .5)\n",
    "        nn.init.uniform_(self.net[0].weight, -bound1, bound1)\n",
    "        nn.init.uniform_(self.net[0].bias, -bound1, bound1)\n",
    "        nn.init.uniform_(self.net[3].weight, -bound2, bound2)\n",
    "        nn.init.uniform_(self.net[0].bias, -bound2, bound2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.dim_head = dim_head\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias=False)\n",
    "        self.to_k = nn.Linear(dim, inner_dim, bias=False)\n",
    "        self.to_v = nn.Linear(dim, inner_dim, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "        self._init_parameters(dim, inner_dim)\n",
    "\n",
    "    def _init_parameters(self, dim, inner_dim):\n",
    "        bound = 1 / (dim ** .5)\n",
    "        nn.init.uniform_(self.to_q.weight, -bound, bound)\n",
    "        nn.init.uniform_(self.to_k.weight, -bound, bound)\n",
    "        nn.init.uniform_(self.to_v.weight, -bound, bound)\n",
    "\n",
    "        bound = 1 / (inner_dim ** .5)\n",
    "        nn.init.uniform_(self.to_out[0].weight, -bound, bound)\n",
    "        nn.init.uniform_(self.to_out[0].bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "\n",
    "        q, k, v = self.to_q(x), self.to_k(x), self.to_v(x)\n",
    "        q = q.reshape(b, n, h, -1).permute(0, 2, 1, 3)\n",
    "        k = k.reshape(b, n, h, -1).permute(0, 2, 1, 3)\n",
    "        v = v.reshape(b, n, h, -1).permute(0, 2, 1, 3)\n",
    "\n",
    "        dots = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = (attn @ v).transpose(1, 2).reshape(b, n, -1)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, window_size=(14, 300), patch_length=10, num_classes=8, dim=64, depth=1, heads=8, mlp_dim=128, pool='cls', dim_head=32, dropout=.2, emb_dropout=0., use_cls_token=True):\n",
    "        super().__init__()\n",
    "\n",
    "        channels, window_length = window_size\n",
    "        num_patches = (window_length // patch_length)\n",
    "        patch_dim = channels * patch_length\n",
    "\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.patch_conv = nn.Conv1d(in_channels=channels, out_channels=dim, kernel_size=patch_length, stride=patch_length, padding=0, bias=True)\n",
    "\n",
    "        self.use_cls_token = use_cls_token\n",
    "        if self.use_cls_token:\n",
    "            self.pos_embedding = nn.Parameter(torch.empty(1, num_patches + 1, dim))\n",
    "        else:\n",
    "            self.pos_embedding = nn.Parameter(torch.empty(1, num_patches, dim))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.empty(1, 1, dim))\n",
    "\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "        self._init_parameters(patch_dim)\n",
    "\n",
    "    def _init_parameters(self, patch_dim):\n",
    "        bound = 1 / (patch_dim ** .5)\n",
    "        nn.init.uniform_(self.patch_conv.weight, -bound, bound)\n",
    "        nn.init.uniform_(self.patch_conv.bias, -bound, bound)\n",
    "        nn.init.zeros_(self.pos_embedding)\n",
    "        nn.init.zeros_(self.mlp_head[1].weight)\n",
    "        nn.init.zeros_(self.mlp_head[1].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_conv(x).flatten(2).transpose(-2, -1)\n",
    "\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        if self.use_cls_token:\n",
    "            cls_tokens = self.cls_token.expand(b, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "            x += self.pos_embedding[:, :(n + 1)]\n",
    "        else :\n",
    "            x += self.pos_embedding\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        x = self.mlp_head(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def load_model(subject, training_fold):\n",
    "    net = ViT()\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    net.load_state_dict((torch.load(f\"checkpoints/vit_subject{subject}_fold{training_fold}.pth\")))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "distributed-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_dir, subject):\n",
    "    \n",
    "    all_other_subjects = ','.join([str(s) for s in range(1, 11) if s != subject])\n",
    "    minmax_picklename = f'./minmax/ds_minmax_sessions=5subjects={all_other_subjects}.pickle'\n",
    "    minmax = load(open(minmax_picklename, 'rb'))\n",
    "    \n",
    "    test_ds = DB6MultiSession(folder=os.path.expanduser(dataset_dir), \n",
    "                              subjects=[subject], sessions=list(range(5, 10)), \n",
    "                              minmax=minmax, n_classes='7+1', steady=True).to(device)\n",
    "    \n",
    "    return test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "different-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax [-0.00820696 -0.00955554 -0.00625532 -0.0054779  -0.00636441 -0.00635652\n",
      " -0.0047272  -0.0016807  -0.01117341 -0.00731644 -0.00749952 -0.00527726\n",
      " -0.0054686  -0.00693581] [0.00775334 0.00828333 0.0070026  0.0048873  0.00684452 0.00630389\n",
      " 0.0061128  0.00096831 0.01065748 0.0073393  0.00718339 0.00572001\n",
      " 0.0059097  0.00688035]\n",
      "minmax [-0.00820696 -0.00955554 -0.00625532 -0.0054779  -0.00636441 -0.00635652\n",
      " -0.0047272  -0.0016807  -0.01117341 -0.00731644 -0.00749952 -0.00527726\n",
      " -0.0054686  -0.00693581] [0.00775334 0.00828333 0.0070026  0.0048873  0.00684452 0.00630389\n",
      " 0.0061128  0.00096831 0.01065748 0.0073393  0.00718339 0.00572001\n",
      " 0.0059097  0.00688035]\n",
      "minmax [-0.00820696 -0.00955554 -0.00625532 -0.0054779  -0.00636441 -0.00635652\n",
      " -0.0047272  -0.0016807  -0.01117341 -0.00731644 -0.00749952 -0.00527726\n",
      " -0.0054686  -0.00693581] [0.00775334 0.00828333 0.0070026  0.0048873  0.00684452 0.00630389\n",
      " 0.0061128  0.00096831 0.01065748 0.0073393  0.00718339 0.00572001\n",
      " 0.0059097  0.00688035]\n",
      "minmax [-0.00820696 -0.00955554 -0.00625532 -0.0054779  -0.00636441 -0.00635652\n",
      " -0.0047272  -0.0016807  -0.01117341 -0.00731644 -0.00749952 -0.00527726\n",
      " -0.0054686  -0.00693581] [0.00775334 0.00828333 0.0070026  0.0048873  0.00684452 0.00630389\n",
      " 0.0061128  0.00096831 0.01065748 0.0073393  0.00718339 0.00572001\n",
      " 0.0059097  0.00688035]\n",
      "minmax [-0.00820696 -0.00955554 -0.00625532 -0.0054779  -0.00636441 -0.00635652\n",
      " -0.0047272  -0.0016807  -0.01117341 -0.00731644 -0.00749952 -0.00527726\n",
      " -0.0054686  -0.00693581] [0.00775334 0.00828333 0.0070026  0.0048873  0.00684452 0.00630389\n",
      " 0.0061128  0.00096831 0.01065748 0.0073393  0.00718339 0.00572001\n",
      " 0.0059097  0.00688035]\n"
     ]
    }
   ],
   "source": [
    "test_ds = load_dataset(dataset_dir='../../dataset_DB6', subject=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "sized-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = load_model(subject=5, training_fold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "protected-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat([s[0] for s in test_ds], dim=0).reshape(-1, 14, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "adolescent-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data[:1000, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "included-champion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(1000, 14, 300, strides=[4200, 300, 1], requires_grad=0, device=cpu),\n",
      "      %pos_embedding : Float(1, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu),\n",
      "      %cls_token : Float(1, 1, 64, strides=[64, 64, 1], requires_grad=1, device=cpu),\n",
      "      %patch_conv.weight : Float(64, 14, 10, strides=[140, 10, 1], requires_grad=1, device=cpu),\n",
      "      %patch_conv.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.norm.weight : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.norm.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.fn.to_q.weight : Float(256, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.fn.to_k.weight : Float(256, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.fn.to_v.weight : Float(256, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.fn.to_out.0.weight : Float(64, 256, strides=[256, 1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.0.fn.to_out.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.1.norm.weight : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.1.norm.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.1.fn.net.0.weight : Float(128, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.1.fn.net.0.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.1.fn.net.3.weight : Float(64, 128, strides=[128, 1], requires_grad=1, device=cpu),\n",
      "      %transformer.layers.0.1.fn.net.3.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %mlp_head.0.weight : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %mlp_head.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %mlp_head.1.weight : Float(8, 64, strides=[64, 1], requires_grad=1, device=cpu),\n",
      "      %mlp_head.1.bias : Float(8, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %22 : Float(1000, 64, 30, strides=[1920, 30, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1], group=1, kernel_shape=[10], pads=[0, 0], strides=[10]](%input, %patch_conv.weight, %patch_conv.bias) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py:295:0\n",
      "  %23 : Long(3, strides=[1], device=cpu) = onnx::Shape(%22)\n",
      "  %24 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %25 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %26 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %27 : Long(2, strides=[1], device=cpu) = onnx::Slice(%23, %25, %26, %24)\n",
      "  %28 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %29 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%27, %28)\n",
      "  %30 : Float(1000, 64, 30, strides=[1920, 30, 1], requires_grad=1, device=cpu) = onnx::Reshape(%22, %29) # <ipython-input-81-45a3ad47a3b7>:156:0\n",
      "  %31 : Float(1000, 30, 64, strides=[1920, 1, 30], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1]](%30) # <ipython-input-81-45a3ad47a3b7>:156:0\n",
      "  %32 : Long(3, strides=[1], device=cpu) = onnx::Shape(%31)\n",
      "  %33 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %34 : Long(device=cpu) = onnx::Gather[axis=0](%32, %33) # <ipython-input-81-45a3ad47a3b7>:158:0\n",
      "  %35 : Long(3, strides=[1], device=cpu) = onnx::Shape(%31)\n",
      "  %36 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %37 : Long(device=cpu) = onnx::Gather[axis=0](%35, %36) # <ipython-input-81-45a3ad47a3b7>:158:0\n",
      "  %38 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %39 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %40 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%34)\n",
      "  %41 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%38)\n",
      "  %42 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%39)\n",
      "  %43 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%40, %41, %42)\n",
      "  %44 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %45 : Long(3, strides=[1], device=cpu) = onnx::Reshape(%43, %44)\n",
      "  %46 : Long(1, strides=[1], device=cpu) = onnx::Shape(%45)\n",
      "  %47 : Long(3, device=cpu) = onnx::ConstantOfShape[value={1}](%46)\n",
      "  %48 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %49 : Long(3, strides=[1], device=cpu) = onnx::Mul(%47, %48)\n",
      "  %50 : Bool(3, strides=[1], device=cpu) = onnx::Equal(%45, %49)\n",
      "  %51 : Long(3, strides=[1], device=cpu) = onnx::Where(%50, %47, %45)\n",
      "  %52 : Float(1000, 1, 64, strides=[0, 64, 1], requires_grad=1, device=cpu) = onnx::Expand(%cls_token, %51) # <ipython-input-81-45a3ad47a3b7>:161:0\n",
      "  %53 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Concat[axis=1](%52, %31) # <ipython-input-81-45a3ad47a3b7>:162:0\n",
      "  %54 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %55 : Long(requires_grad=0, device=cpu) = onnx::Add(%37, %54)\n",
      "  %56 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %57 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %58 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%57)\n",
      "  %59 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%55)\n",
      "  %60 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%56)\n",
      "  %61 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %62 : Float(1, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Slice(%pos_embedding, %58, %59, %60, %61)\n",
      "  %63 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%53, %62) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1168:0\n",
      "  %64 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::ATen[cudnn_enable=1, eps=1.0000000000000001e-05, normalized_shape=[64], operator=\"layer_norm\"](%63, %transformer.layers.0.0.norm.weight, %transformer.layers.0.0.norm.bias) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2346:0\n",
      "  %65 : Long(3, strides=[1], device=cpu) = onnx::Shape(%64)\n",
      "  %66 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %67 : Long(device=cpu) = onnx::Gather[axis=0](%65, %66) # <ipython-input-81-45a3ad47a3b7>:84:0\n",
      "  %68 : Long(3, strides=[1], device=cpu) = onnx::Shape(%64)\n",
      "  %69 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %70 : Long(device=cpu) = onnx::Gather[axis=0](%68, %69) # <ipython-input-81-45a3ad47a3b7>:84:0\n",
      "  %71 : Float(64, 256, strides=[256, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%transformer.layers.0.0.fn.to_q.weight)\n",
      "  %72 : Float(1000, 31, 256, strides=[7936, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%64, %71) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %73 : Float(64, 256, strides=[256, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%transformer.layers.0.0.fn.to_k.weight)\n",
      "  %74 : Float(1000, 31, 256, strides=[7936, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%64, %73) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %75 : Float(64, 256, strides=[256, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%transformer.layers.0.0.fn.to_v.weight)\n",
      "  %76 : Float(1000, 31, 256, strides=[7936, 256, 1], requires_grad=1, device=cpu) = onnx::MatMul(%64, %75) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %77 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %78 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %79 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%67)\n",
      "  %80 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%70)\n",
      "  %81 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%77)\n",
      "  %82 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%78)\n",
      "  %83 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%79, %80, %81, %82)\n",
      "  %84 : Float(1000, 31, 8, 32, strides=[7936, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%72, %83) # <ipython-input-81-45a3ad47a3b7>:87:0\n",
      "  %85 : Float(1000, 8, 31, 32, strides=[7936, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%84) # <ipython-input-81-45a3ad47a3b7>:87:0\n",
      "  %86 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %87 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %88 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%67)\n",
      "  %89 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%70)\n",
      "  %90 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%86)\n",
      "  %91 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%87)\n",
      "  %92 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%88, %89, %90, %91)\n",
      "  %93 : Float(1000, 31, 8, 32, strides=[7936, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%74, %92) # <ipython-input-81-45a3ad47a3b7>:88:0\n",
      "  %94 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "  %95 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %96 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%67)\n",
      "  %97 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%70)\n",
      "  %98 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%94)\n",
      "  %99 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%95)\n",
      "  %100 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%96, %97, %98, %99)\n",
      "  %101 : Float(1000, 31, 8, 32, strides=[7936, 256, 32, 1], requires_grad=1, device=cpu) = onnx::Reshape(%76, %100) # <ipython-input-81-45a3ad47a3b7>:89:0\n",
      "  %102 : Float(1000, 8, 31, 32, strides=[7936, 32, 256, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%101) # <ipython-input-81-45a3ad47a3b7>:89:0\n",
      "  %103 : Float(1000, 8, 32, 31, strides=[7936, 32, 1, 256], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%93) # <ipython-input-81-45a3ad47a3b7>:91:0\n",
      "  %104 : Float(1000, 8, 31, 31, strides=[7688, 961, 31, 1], requires_grad=1, device=cpu) = onnx::MatMul(%85, %103) # <ipython-input-81-45a3ad47a3b7>:91:0\n",
      "  %105 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.176777}]()\n",
      "  %106 : Float(1000, 8, 31, 31, strides=[7688, 961, 31, 1], requires_grad=1, device=cpu) = onnx::Mul(%104, %105)\n",
      "  %107 : Float(1000, 8, 31, 31, strides=[7688, 961, 31, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%106) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1679:0\n",
      "  %108 : Float(1000, 8, 31, 32, strides=[7936, 992, 32, 1], requires_grad=1, device=cpu) = onnx::MatMul(%107, %102) # <ipython-input-81-45a3ad47a3b7>:94:0\n",
      "  %109 : Float(1000, 31, 8, 32, strides=[7936, 32, 992, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%108) # <ipython-input-81-45a3ad47a3b7>:94:0\n",
      "  %110 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %111 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%67)\n",
      "  %112 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%70)\n",
      "  %113 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%110)\n",
      "  %114 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%111, %112, %113)\n",
      "  %115 : Float(1000, 31, 256, strides=[7936, 256, 1], requires_grad=1, device=cpu) = onnx::Reshape(%109, %114) # <ipython-input-81-45a3ad47a3b7>:94:0\n",
      "  %116 : Float(256, 64, strides=[64, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%transformer.layers.0.0.fn.to_out.0.weight)\n",
      "  %117 : Float(1000, 31, 64, strides=[1984, 64, 1], device=cpu) = onnx::MatMul(%115, %116)\n",
      "  %118 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%transformer.layers.0.0.fn.to_out.0.bias, %117) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1168:0\n",
      "  %119 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%118, %63) # <ipython-input-81-45a3ad47a3b7>:109:0\n",
      "  %120 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::ATen[cudnn_enable=1, eps=1.0000000000000001e-05, normalized_shape=[64], operator=\"layer_norm\"](%119, %transformer.layers.0.1.norm.weight, %transformer.layers.0.1.norm.bias) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2346:0\n",
      "  %121 : Float(64, 128, strides=[128, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%transformer.layers.0.1.fn.net.0.weight)\n",
      "  %122 : Float(1000, 31, 128, strides=[3968, 128, 1], device=cpu) = onnx::MatMul(%120, %121)\n",
      "  %123 : Float(1000, 31, 128, strides=[3968, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%transformer.layers.0.1.fn.net.0.bias, %122) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  %124 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
      "  %125 : Float(1000, 31, 128, strides=[3968, 128, 1], device=cpu) = onnx::Div(%123, %124)\n",
      "  %126 : Float(1000, 31, 128, strides=[3968, 128, 1], device=cpu) = onnx::Erf(%125)\n",
      "  %127 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %128 : Float(1000, 31, 128, strides=[3968, 128, 1], device=cpu) = onnx::Add(%126, %127)\n",
      "  %129 : Float(1000, 31, 128, strides=[3968, 128, 1], device=cpu) = onnx::Mul(%123, %128)\n",
      "  %130 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "  %131 : Float(1000, 31, 128, strides=[3968, 128, 1], requires_grad=1, device=cpu) = onnx::Mul(%129, %130) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1168:0\n",
      "  %132 : Float(128, 64, strides=[64, 1], device=cpu) = onnx::Transpose[perm=[1, 0]](%transformer.layers.0.1.fn.net.3.weight)\n",
      "  %133 : Float(1000, 31, 64, strides=[1984, 64, 1], device=cpu) = onnx::MatMul(%131, %132)\n",
      "  %134 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%transformer.layers.0.1.fn.net.3.bias, %133) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1168:0\n",
      "  %135 : Float(1000, 31, 64, strides=[1984, 64, 1], requires_grad=1, device=cpu) = onnx::Add(%134, %119) # <ipython-input-81-45a3ad47a3b7>:171:0\n",
      "  %136 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %137 : Float(1000, 64, strides=[1984, 1], requires_grad=1, device=cpu) = onnx::Gather[axis=1](%135, %136) # <ipython-input-81-45a3ad47a3b7>:171:0\n",
      "  %138 : Float(1000, 64, strides=[64, 1], requires_grad=1, device=cpu) = onnx::ATen[cudnn_enable=1, eps=1.0000000000000001e-05, normalized_shape=[64], operator=\"layer_norm\"](%137, %mlp_head.0.weight, %mlp_head.0.bias) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:2346:0\n",
      "  %output : Float(1000, 8, strides=[8, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%138, %mlp_head.1.weight, %mlp_head.1.bias) # c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\functional.py:1847:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "ONNX_PATH=\"./my_model.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model=pytorch_model,\n",
    "    args=data_, \n",
    "    f=ONNX_PATH, # where should it be saved\n",
    "    verbose=True,\n",
    "    export_params=True,\n",
    "    do_constant_folding=False,  # fold constant values for optimization\n",
    "    # do_constant_folding=True,   # fold constant values for optimization\n",
    "    opset_version=10, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "    input_names=['input'],\n",
    "    output_names=['output']\n",
    ")\n",
    "onnx_model = onnx.load(ONNX_PATH)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "artificial-riding",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ModelProto' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-a53dd2796d36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0monnx_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'ModelProto' object is not callable"
     ]
    }
   ],
   "source": [
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "generic-simpson",
   "metadata": {},
   "outputs": [
    {
     "ename": "BackendIsNotSupposedToImplementIt",
     "evalue": "in user code:\n\n    c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\onnx_tf\\backend_tf_module.py:99 __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\onnx_tf\\backend.py:338 _onnx_node_to_tensorflow_op  *\n        raise BackendIsNotSupposedToImplementIt(\"{} is not implemented.\".format(\n\n    BackendIsNotSupposedToImplementIt: ATen is not implemented.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBackendIsNotSupposedToImplementIt\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-36465adf616b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# model associated with the backend representation and serializes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# to a protobuf file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtf_rep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTF_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\onnx_tf\\backend_rep.py\u001b[0m in \u001b[0;36mexport_graph\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         signatures=self.tf_module.__call__.get_concrete_function(\n\u001b[1;32m--> 133\u001b[1;33m             **self.signatures))\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_export\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1231\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m     \u001b[1;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1233\u001b[1;33m     \u001b[0mconcrete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1234\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 760\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3308\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3988\u001b[0m     \u001b[1;31m# However, the replacer is still responsible for attaching self properly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m     \u001b[1;31m# TODO(mdan): Is it possible to do it here instead?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3990\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3991\u001b[0m   \u001b[0mweak_bound_method_wrapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_method_wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBackendIsNotSupposedToImplementIt\u001b[0m: in user code:\n\n    c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\onnx_tf\\backend_tf_module.py:99 __call__  *\n        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,\n    c:\\users\\francesco\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\onnx_tf\\backend.py:338 _onnx_node_to_tensorflow_op  *\n        raise BackendIsNotSupposedToImplementIt(\"{} is not implemented.\".format(\n\n    BackendIsNotSupposedToImplementIt: ATen is not implemented.\n"
     ]
    }
   ],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "\n",
    "TF_PATH = \"./my_tf_model.pb\" # where the representation of tensorflow model will be stored\n",
    "ONNX_PATH = \"./my_model.onnx\" # path to my existing ONNX model\n",
    "onnx_model = onnx.load(ONNX_PATH)  # load onnx model\n",
    "\n",
    "# prepare function converts an ONNX model to an internel representation\n",
    "# of the computational graph called TensorflowRep and returns\n",
    "# the converted representation.\n",
    "tf_rep = prepare(onnx_model)  # creating TensorflowRep object\n",
    "\n",
    "# export_graph function obtains the graph proto corresponding to the ONNX\n",
    "# model associated with the backend representation and serializes\n",
    "# to a protobuf file.\n",
    "tf_rep.export_graph(TF_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
